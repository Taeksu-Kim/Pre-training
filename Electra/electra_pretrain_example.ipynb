{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-6uGidgK6Iz",
        "outputId": "9ae690d9-7a00-42aa-c8da-a8ada6cdeed1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (5.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.9.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Taeksu-Kim/Pre-training.git"
      ],
      "metadata": {
        "id": "xtrEPOHPWrSO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fb07802-6d91-4fa9-897f-65c36b215374"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Pre-training' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd Pre-training/Electra"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7KV-T4lWr12",
        "outputId": "15396ada-ffd0-4ee3-b1e6-fea3f84e22d7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Pre-training/Electra\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir my_data"
      ],
      "metadata": {
        "id": "qLlB0IIUq10o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ab03fb8-0dde-4f97-d29a-02e915461e0d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘my_data’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체적인 동작 확인을 위한 작은 데이터셋\n",
        "!curl -c ./cookie -s -L \"https://drive.google.com/uc?export=download&id=1zib1GI8Q5wV08TgYBa2GagqNh4jyfXZz\" > /dev/null\n",
        "!curl -Lb ./cookie \"https://drive.google.com/uc?export=download&confirm=`awk '/download/ {print $NF}' ./cookie`&id=1zib1GI8Q5wV08TgYBa2GagqNh4jyfXZz\" -o my_data/wiki_20190620_small.txt\n",
        "\n",
        "file=\"./my_data/wiki_20190620_small.txt\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AzPAoJsq13O",
        "outputId": "019b71c4-45e2-44ff-fc09-a17453505249"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "awk: cannot open ./cookie (No such file or directory)\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 1323k  100 1323k    0     0  1360k      0 --:--:-- --:--:-- --:--:-- 1360k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from time import time\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "\n",
        "from transformers import ElectraModel, ElectraConfig, ElectraForMaskedLM, ElectraTokenizerFast\n",
        "\n",
        "# custom_lib\n",
        "from custom_tokenizer import Build_Tokenizer\n",
        "from processor import TextDatasetForNextSentencePrediction\n",
        "from model import custom_Electra"
      ],
      "metadata": {
        "id": "f_lAJFyeq17Y"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed):\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def set_cuda(deterministic=True):\n",
        "    if torch.cuda.is_available():\n",
        "        torch.backends.cudnn.deterministic = deterministic\n",
        "        torch.backends.cudnn.benchmark = not deterministic\n",
        "\n",
        "set_seed(42)\n",
        "set_cuda()"
      ],
      "metadata": {
        "id": "5xLmjy_DJCjS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_courpus_files = ['./my_data/wiki_20190620_small.txt']\n",
        "tokenizer_save_dir = './Tokenizer'\n",
        "model_max_input_len = 512\n",
        "\n",
        "Build_Tokenizer(input_courpus_files,\n",
        "                tokenizer_save_dir,\n",
        "                vocab_size=35000,\n",
        "                special_tokens=[\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"],\n",
        "                model_max_input_len=512,\n",
        "                clean_text=True,\n",
        "                handle_chinese_chars=True,\n",
        "                strip_accents=False,\n",
        "                lowercase=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzp8dwa4q19-",
        "outputId": "7c1cfe83-5026-4d8a-bfe5-9ce9167479a3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab.txt is saved in ./Tokenizer\n",
            "Electra Tokenizer is saved in ./Tokenizer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = ElectraTokenizerFast.from_pretrained(tokenizer_save_dir)"
      ],
      "metadata": {
        "id": "1LWHNPscq2Ak"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_max_input_len = 512\n",
        "\n",
        "dataset = TextDatasetForNextSentencePrediction(\n",
        "    tokenizer=tokenizer,\n",
        "    file_path='/content/Pre-training/Electra/my_data/wiki_20190620_small.txt',\n",
        "    block_size=model_max_input_len,\n",
        "    num_min_lines=5,\n",
        "    overwrite_cache=False,\n",
        "    full_seq_probability=0.65,\n",
        ")"
      ],
      "metadata": {
        "id": "cGrpp3Wo7mrl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 4\n",
        "epochs = 100\n",
        "learning_rate = 1e-5\n",
        "weight_decay = 1e-2\n",
        "early_stopping_patience = 10\n",
        "\n",
        "use_scaler = False\n",
        "use_scheduler = False\n",
        "\n",
        "save_name = 'electra_pretraining'\n",
        "\n",
        "distributed_enabled = False\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "J84P4z7-7muL"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=0, shuffle=True)"
      ],
      "metadata": {
        "id": "Nvz7X532eotc"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in train_dataloader:\n",
        "  break"
      ],
      "metadata": {
        "id": "JQc1DJmG7mxX"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgG49w7LOZT1",
        "outputId": "37579725-28b0-4045-8df4-a73421eba465"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[    2, 25287, 24311,  ...,     0,     0,     0],\n",
              "         [    2,  9100,  1066,  ...,     0,     0,     0],\n",
              "         [    2,  1928,    33,  ...,     0,     0,     0],\n",
              "         [    2,   707,  4638,  ...,     0,     0,     0]]),\n",
              " 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0]]),\n",
              " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0]])}"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X_XGmoyUOZWj"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import ElectraConfig, ElectraForMaskedLM, ElectraForPreTraining\n",
        "\n",
        "hidden_size = 768\n",
        "embedding_size = 768\n",
        "\n",
        "# generator config\n",
        "gen_config = ElectraConfig()\n",
        "gen_config.hidden_size = hidden_size\n",
        "gen_config.embedding_size = embedding_size\n",
        "gen_config.num_attention_heads = 4\n",
        "gen_config.vocab_size = tokenizer.vocab_size\n",
        "\n",
        "# discriminator config\n",
        "disc_config = ElectraConfig()\n",
        "disc_config.hidden_size = hidden_size\n",
        "disc_config.embedding_size = embedding_size\n",
        "disc_config.num_attention_heads = 12\n",
        "disc_config.vocab_size = tokenizer.vocab_size"
      ],
      "metadata": {
        "id": "PYFPxPWdFBMP"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tie_weights(generator, discriminator):\n",
        "    generator.electra.embeddings.word_embeddings = discriminator.electra.embeddings.word_embeddings\n",
        "    generator.electra.embeddings.position_embeddings = discriminator.electra.embeddings.position_embeddings\n",
        "    generator.electra.embeddings.token_type_embeddings = discriminator.electra.embeddings.token_type_embeddings"
      ],
      "metadata": {
        "id": "bOWs8Jd6b003"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = ElectraForMaskedLM(gen_config)\n",
        "discriminator = ElectraForPreTraining(disc_config)\n",
        "tie_weights(generator, discriminator)"
      ],
      "metadata": {
        "id": "mMQquahhGrA7"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = custom_Electra(\n",
        "    generator,\n",
        "    discriminator,\n",
        "    num_tokens = tokenizer.vocab_size,\n",
        "    mask_token_id = tokenizer.mask_token_id,\n",
        "    pad_token_id = tokenizer.pad_token_id,\n",
        "    mask_prob = 0.15,\n",
        "    mask_ignore_token_ids = [tokenizer.vocab['[CLS]'], tokenizer.vocab['[SEP]']],\n",
        "    random_token_prob = 0.0)\n",
        "\n",
        "if distributed_enabled:\n",
        "    model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[rank], find_unused_parameters=True)\n",
        "\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "rC6zU5PmEJZr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c951f170-3aa2-4b0b-8ec2-c9a39316d1b8"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "custom_Electra(\n",
              "  (generator): ElectraForMaskedLM(\n",
              "    (electra): ElectraModel(\n",
              "      (embeddings): ElectraEmbeddings(\n",
              "        (word_embeddings): Embedding(25722, 768, padding_idx=0)\n",
              "        (position_embeddings): Embedding(512, 768)\n",
              "        (token_type_embeddings): Embedding(2, 768)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (encoder): ElectraEncoder(\n",
              "        (layer): ModuleList(\n",
              "          (0): ElectraLayer(\n",
              "            (attention): ElectraAttention(\n",
              "              (self): ElectraSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): ElectraSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): ElectraIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=1024, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): ElectraOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (1): ElectraLayer(\n",
              "            (attention): ElectraAttention(\n",
              "              (self): ElectraSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): ElectraSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): ElectraIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=1024, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): ElectraOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (2): ElectraLayer(\n",
              "            (attention): ElectraAttention(\n",
              "              (self): ElectraSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): ElectraSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): ElectraIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=1024, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): ElectraOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (3): ElectraLayer(\n",
              "            (attention): ElectraAttention(\n",
              "              (self): ElectraSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): ElectraSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): ElectraIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=1024, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): ElectraOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (4): ElectraLayer(\n",
              "            (attention): ElectraAttention(\n",
              "              (self): ElectraSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): ElectraSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): ElectraIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=1024, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): ElectraOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (5): ElectraLayer(\n",
              "            (attention): ElectraAttention(\n",
              "              (self): ElectraSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): ElectraSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): ElectraIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=1024, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): ElectraOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (6): ElectraLayer(\n",
              "            (attention): ElectraAttention(\n",
              "              (self): ElectraSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): ElectraSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): ElectraIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=1024, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): ElectraOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (7): ElectraLayer(\n",
              "            (attention): ElectraAttention(\n",
              "              (self): ElectraSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): ElectraSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): ElectraIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=1024, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): ElectraOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (8): ElectraLayer(\n",
              "            (attention): ElectraAttention(\n",
              "              (self): ElectraSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): ElectraSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): ElectraIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=1024, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): ElectraOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (9): ElectraLayer(\n",
              "            (attention): ElectraAttention(\n",
              "              (self): ElectraSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): ElectraSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): ElectraIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=1024, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): ElectraOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (10): ElectraLayer(\n",
              "            (attention): ElectraAttention(\n",
              "              (self): ElectraSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): ElectraSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): ElectraIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=1024, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): ElectraOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (11): ElectraLayer(\n",
              "            (attention): ElectraAttention(\n",
              "              (self): ElectraSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): ElectraSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): ElectraIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=1024, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): ElectraOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (generator_predictions): ElectraGeneratorPredictions(\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    )\n",
              "    (generator_lm_head): Linear(in_features=768, out_features=25722, bias=True)\n",
              "  )\n",
              "  (discriminator): ElectraForPreTraining(\n",
              "    (electra): ElectraModel(\n",
              "      (embeddings): ElectraEmbeddings(\n",
              "        (word_embeddings): Embedding(25722, 768, padding_idx=0)\n",
              "        (position_embeddings): Embedding(512, 768)\n",
              "        (token_type_embeddings): Embedding(2, 768)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (encoder): ElectraEncoder(\n",
              "        (layer): ModuleList(\n",
              "          (0): ElectraLayer(\n",
              "            (attention): ElectraAttention(\n",
              "              (self): ElectraSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): ElectraSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): ElectraIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=1024, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): ElectraOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (1): ElectraLayer(\n",
              "            (attention): ElectraAttention(\n",
              "              (self): ElectraSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): ElectraSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): ElectraIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=1024, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): ElectraOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (2): ElectraLayer(\n",
              "            (attention): ElectraAttention(\n",
              "              (self): ElectraSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): ElectraSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): ElectraIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=1024, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): ElectraOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (3): ElectraLayer(\n",
              "            (attention): ElectraAttention(\n",
              "              (self): ElectraSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): ElectraSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): ElectraIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=1024, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): ElectraOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (4): ElectraLayer(\n",
              "            (attention): ElectraAttention(\n",
              "              (self): ElectraSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): ElectraSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): ElectraIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=1024, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): ElectraOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (5): ElectraLayer(\n",
              "            (attention): ElectraAttention(\n",
              "              (self): ElectraSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): ElectraSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): ElectraIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=1024, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): ElectraOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (6): ElectraLayer(\n",
              "            (attention): ElectraAttention(\n",
              "              (self): ElectraSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): ElectraSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): ElectraIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=1024, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): ElectraOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (7): ElectraLayer(\n",
              "            (attention): ElectraAttention(\n",
              "              (self): ElectraSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): ElectraSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): ElectraIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=1024, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): ElectraOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (8): ElectraLayer(\n",
              "            (attention): ElectraAttention(\n",
              "              (self): ElectraSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): ElectraSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): ElectraIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=1024, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): ElectraOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (9): ElectraLayer(\n",
              "            (attention): ElectraAttention(\n",
              "              (self): ElectraSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): ElectraSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): ElectraIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=1024, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): ElectraOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (10): ElectraLayer(\n",
              "            (attention): ElectraAttention(\n",
              "              (self): ElectraSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): ElectraSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): ElectraIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=1024, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): ElectraOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (11): ElectraLayer(\n",
              "            (attention): ElectraAttention(\n",
              "              (self): ElectraSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): ElectraSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): ElectraIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=1024, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): ElectraOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (discriminator_predictions): ElectraDiscriminatorPredictions(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (dense_prediction): Linear(in_features=768, out_features=1, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_params_without_weight_decay_ln(named_params, weight_decay):\n",
        "    no_decay = ['bias', 'LayerNorm.weight']\n",
        "    optimizer_grouped_parameters = [\n",
        "        {\n",
        "            'params': [p for n, p in named_params if not any(nd in n for nd in no_decay)],\n",
        "            'weight_decay': weight_decay,\n",
        "        },\n",
        "        {\n",
        "            'params': [p for n, p in named_params if any(nd in n for nd in no_decay)],\n",
        "            'weight_decay': 0.0,\n",
        "        },\n",
        "    ]\n",
        "    return optimizer_grouped_parameters\n",
        "\n",
        "def get_linear_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps, last_epoch=-1):\n",
        "    def lr_lambda(current_step):\n",
        "        learning_rate = max(0.0, 1. - (float(current_step) / float(num_training_steps)))\n",
        "        learning_rate *= min(1.0, float(current_step) / float(num_warmup_steps))\n",
        "        return learning_rate\n",
        "    return LambdaLR(optimizer, lr_lambda, last_epoch)"
      ],
      "metadata": {
        "id": "3i1WdmQoIS8S"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_training_steps = len(train_dataloader) * epochs\n",
        "num_warmup_steps = num_training_steps * 0.05"
      ],
      "metadata": {
        "id": "6GxnRN6oUF1x"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(get_params_without_weight_decay_ln(model.named_parameters(), weight_decay=weight_decay), lr=learning_rate)"
      ],
      "metadata": {
        "id": "vZUrNEPyeFlK"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = torch.cuda.amp.GradScaler(enabled=True)"
      ],
      "metadata": {
        "id": "ROmdX1vLEHyA"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps)"
      ],
      "metadata": {
        "id": "nAJfxrc5TmK4"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class color:\n",
        "PURPLE = '\\033[95m'\n",
        "CYAN = '\\033[96m'\n",
        "DARKCYAN = '\\033[36m'\n",
        "BLUE = '\\033[94m'\n",
        "GREEN = '\\033[92m'\n",
        "YELLOW = '\\033[93m'\n",
        "RED = '\\033[91m'\n",
        "BOLD = '\\033[1m'\n",
        "UNDERLINE = '\\033[4m'\n",
        "END = '\\033[0m'"
      ],
      "metadata": {
        "id": "yjP7TnMhKd48"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(batch, epoch, training):\n",
        "    batch = {key: value.to(device) for key, value in batch.items()}\n",
        "\n",
        "    if training is True:\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "\n",
        "            loss, loss_mlm, loss_disc, acc_gen, acc_disc, disc_labels, disc_pred = model(**batch)\n",
        "\n",
        "        if use_scaler:\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.unscale_(optimizer)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "        else:\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        if use_scheduler:\n",
        "            lr = scheduler.get_last_lr()[0]\n",
        "\n",
        "        else:\n",
        "            lr = optimizer.param_groups[0][\"lr\"]\n",
        "\n",
        "        return loss, loss_mlm, loss_disc, acc_gen, acc_disc, round(lr, 10)"
      ],
      "metadata": {
        "id": "7maFdm8VKd7X"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# train\n",
        "\n",
        "loss_plot = []\n",
        "lrs = []\n",
        "\n",
        "check_list = []\n",
        "\n",
        "best_loss = float('inf')\n",
        "\n",
        "best_epoch = 0\n",
        "patience = 0\n",
        "\n",
        "step = 0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    gc.collect()\n",
        "    total_loss = 0\n",
        "    total_loss_mlm = 0\n",
        "    total_loss_disc = 0\n",
        "    total_acc_gen = 0\n",
        "    total_acc_disc = 0\n",
        "\n",
        "    \n",
        "    tqdm_dataset = tqdm(enumerate(train_dataloader), total=train_dataloader.__len__())\n",
        "    training = True\n",
        "    for batch_idx, batch in tqdm_dataset:\n",
        "        step += 1\n",
        "\n",
        "        loss, loss_mlm, loss_disc, acc_gen, acc_disc, lr = train_step(batch, epoch, training)\n",
        "        total_loss += loss\n",
        "        total_loss_mlm += loss_mlm\n",
        "        total_loss_disc += loss_disc\n",
        "        total_acc_gen += acc_gen\n",
        "        total_acc_disc += acc_disc\n",
        "\n",
        "        \n",
        "        tqdm_dataset.set_postfix({\n",
        "            'step' : step,\n",
        "            'Epoch': epoch + 1,\n",
        "            GREEN + 'Loss' : '{:.4f}'.format(total_loss/(batch_idx+1)) + END,\n",
        "            'mlm_loss' : '{:.4f}'.format(total_loss_mlm/(batch_idx+1)),\n",
        "            'mlm_acc' : '{:.4f}'.format(total_acc_gen/(batch_idx+1)),\n",
        "            'disc_loss' : '{:.4f}'.format(total_loss_disc/(batch_idx+1)),\n",
        "            'disc_acc' : '{:.4f}'.format(total_acc_disc/(batch_idx+1)),\n",
        "            'LR' : lr,\n",
        "        })\n",
        "            \n",
        "    loss_plot.append(total_loss/(batch_idx+1))\n",
        "    \n",
        "    cur_loss = round(float((total_loss/(batch_idx+1)).detach().cpu()), 3)\n",
        "\n",
        "    if cur_loss < best_loss:\n",
        "        print(YELLOW + 'Best_loss is updated from {:>5} to {:>5} on epoch {}'.format(best_loss, cur_loss, epoch+1) + END)\n",
        "        best_loss = cur_loss\n",
        "        best_epoch = epoch+1\n",
        "        torch.save(model.state_dict(), './'+save_name+'.ckpt')\n",
        "        patience = 0\n",
        "    else:\n",
        "        patience += 1\n",
        "    \n",
        "    lrs.append(lr)\n",
        "    \n",
        "    if patience == early_stopping_patience:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxVX9QT_cR61",
        "outputId": "cd0df508-1d5e-47e6-9361-512a6ffbd748"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 184/184 [01:35<00:00,  1.92it/s, step=184, Epoch=1, \u001b[92mLoss=40.7193\u001b[0m, mlm_loss=10.3590, mlm_acc=0.0000, disc_loss=0.6072, disc_acc=0.5017, LR=0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[93mBest_loss is updated from   inf to 40.719 on epoch 1\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 184/184 [01:35<00:00,  1.92it/s, step=368, Epoch=2, \u001b[92mLoss=40.7275\u001b[0m, mlm_loss=10.3662, mlm_acc=0.0000, disc_loss=0.6072, disc_acc=0.5015, LR=0]\n",
            "100%|██████████| 184/184 [01:35<00:00,  1.93it/s, step=552, Epoch=3, \u001b[92mLoss=40.7169\u001b[0m, mlm_loss=10.3581, mlm_acc=0.0001, disc_loss=0.6072, disc_acc=0.5014, LR=0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[93mBest_loss is updated from 40.719 to 40.717 on epoch 3\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 184/184 [01:35<00:00,  1.93it/s, step=736, Epoch=4, \u001b[92mLoss=40.7099\u001b[0m, mlm_loss=10.3681, mlm_acc=0.0001, disc_loss=0.6068, disc_acc=0.5018, LR=0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[93mBest_loss is updated from 40.717 to 40.71 on epoch 4\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 184/184 [01:35<00:00,  1.93it/s, step=920, Epoch=5, \u001b[92mLoss=40.7161\u001b[0m, mlm_loss=10.3656, mlm_acc=0.0000, disc_loss=0.6070, disc_acc=0.5020, LR=0]\n",
            "100%|██████████| 184/184 [01:35<00:00,  1.93it/s, step=1104, Epoch=6, \u001b[92mLoss=40.7225\u001b[0m, mlm_loss=10.3629, mlm_acc=0.0000, disc_loss=0.6072, disc_acc=0.5017, LR=0]\n",
            "100%|██████████| 184/184 [01:35<00:00,  1.93it/s, step=1288, Epoch=7, \u001b[92mLoss=40.7172\u001b[0m, mlm_loss=10.3560, mlm_acc=0.0000, disc_loss=0.6072, disc_acc=0.5015, LR=0]\n",
            "100%|██████████| 184/184 [01:35<00:00,  1.93it/s, step=1472, Epoch=8, \u001b[92mLoss=40.7142\u001b[0m, mlm_loss=10.3567, mlm_acc=0.0001, disc_loss=0.6071, disc_acc=0.5013, LR=0]\n",
            "100%|██████████| 184/184 [01:35<00:00,  1.93it/s, step=1656, Epoch=9, \u001b[92mLoss=40.7138\u001b[0m, mlm_loss=10.3553, mlm_acc=0.0000, disc_loss=0.6072, disc_acc=0.5021, LR=0]\n",
            "100%|██████████| 184/184 [01:35<00:00,  1.93it/s, step=1840, Epoch=10, \u001b[92mLoss=40.7176\u001b[0m, mlm_loss=10.3612, mlm_acc=0.0000, disc_loss=0.6071, disc_acc=0.5018, LR=0]\n",
            "100%|██████████| 184/184 [01:35<00:00,  1.93it/s, step=2024, Epoch=11, \u001b[92mLoss=40.7265\u001b[0m, mlm_loss=10.3607, mlm_acc=0.0000, disc_loss=0.6073, disc_acc=0.5020, LR=0]\n",
            "100%|██████████| 184/184 [01:35<00:00,  1.93it/s, step=2208, Epoch=12, \u001b[92mLoss=40.7184\u001b[0m, mlm_loss=10.3588, mlm_acc=0.0000, disc_loss=0.6072, disc_acc=0.5020, LR=0]\n",
            "100%|██████████| 184/184 [01:35<00:00,  1.93it/s, step=2392, Epoch=13, \u001b[92mLoss=40.7245\u001b[0m, mlm_loss=10.3631, mlm_acc=0.0001, disc_loss=0.6072, disc_acc=0.5015, LR=0]\n",
            "100%|██████████| 184/184 [01:35<00:00,  1.93it/s, step=2576, Epoch=14, \u001b[92mLoss=40.7178\u001b[0m, mlm_loss=10.3572, mlm_acc=0.0000, disc_loss=0.6072, disc_acc=0.5017, LR=0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 16min 29s, sys: 6min 1s, total: 22min 30s\n",
            "Wall time: 22min 23s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.discriminator.save_pretrained('./electra_model')"
      ],
      "metadata": {
        "id": "R-0NXG3zcSM9"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlm_model = ElectraForMaskedLM.from_pretrained('./electra_model')\n",
        "mlm_model.eval()\n",
        "\n",
        "inputs = tokenizer(\"한국의 수도는 [MASK]이다.\", return_tensors=\"pt\")\n",
        "\n",
        "logits = mlm_model(**inputs)['logits']\n",
        "\n",
        "tokenizer.decode(torch.argmax(logits[0,inputs.input_ids[0].tolist().index(tokenizer.mask_token_id)], dim=-1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "QfWtSXOPlPTZ",
        "outputId": "d7c4951c-523b-4aaa-e657-294339031c82"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at ./electra_model were not used when initializing ElectraForMaskedLM: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.bias']\n",
            "- This IS expected if you are initializing ElectraForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ElectraForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of ElectraForMaskedLM were not initialized from the model checkpoint at ./electra_model and are newly initialized: ['generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.dense.bias', 'generator_predictions.dense.weight', 'generator_predictions.LayerNorm.weight', 'generator_lm_head.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'자생한다'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "disc_model = ElectraForPreTraining.from_pretrained('./electra_model')\n",
        "disc_model.eval()\n",
        "\n",
        "inputs = tokenizer(\"한국의 수도는 부산이다.\", return_tensors=\"pt\")\n",
        "\n",
        "logits = disc_model(**inputs)['logits']\n",
        "logits = torch.sigmoid(logits)"
      ],
      "metadata": {
        "id": "yRD18nTOo3-1"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(inputs.input_ids[0].tolist())):\n",
        "  print('{} : {}'.format(tokenizer.convert_ids_to_tokens(inputs.input_ids[0].tolist()[i]), round(float(logits[0][i]), 3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JwxKPrIo4Bq",
        "outputId": "d8d7e250-d3b4-4d51-cc7d-b12c9e7c57a5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS] : 0.417\n",
            "한국의 : 0.415\n",
            "수도는 : 0.412\n",
            "부산 : 0.428\n",
            "##이다 : 0.446\n",
            ". : 0.399\n",
            "[SEP] : 0.435\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FatnL9yVwlGO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}